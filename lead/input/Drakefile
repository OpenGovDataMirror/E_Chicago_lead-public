; Input drake file for loading data into the database.

; $INPUT is path to folder containing single shp file
; $OUTPUT is path sql success file, which determines import table and schema
; shapefile is converted to 4326 using ogr2ogr before import
import_shapefile()
    BASENAME=$(basename $(ls $INPUT/*.shp))
    # get table name from output, e.g. change $[SQL_DIR]/input/wards gives input.wards
    TABLENAME=$(echo $OUTPUT | sed 's/^.*\/\(.*\)\/\(.*\)$/\1.\2/')
    # ogr2ogr doesn't like an existing file
    rm -rfv "$INPUT"/4326/ && mkdir -p $INPUT/4326/
    psql -v ON_ERROR_STOP=1 -c "DROP TABLE IF EXISTS $TABLENAME"
    # -q suppresses query output which for large shapefiles seems to slow down the import
    ogr2ogr -t_srs EPSG:4326 $INPUT/4326/$BASENAME $INPUT/$BASENAME &&\
    shp2pgsql -I -D -s 4326 $INPUT/4326/$BASENAME $TABLENAME | psql -v ON_ERROR_STOP=1 -q && touch $OUTPUT


import_dbf()
    SCHEMA=$(basename $(dirname $OUTPUT))
    TABLE=$(basename $OUTPUT)
    ogr2ogr -f PostgreSQL PG:"dbname='$PGDATABASE' host='$PGHOST' user='$PGUSER'" $INPUT -lco "schema=$SCHEMA" -lco 'overwrite=yes' -nln $TABLE && touch $OUTPUT

; $URL is a source url
; $OUTPUT0 is a target for the zip file
; $OUTPUT1 is a directory to unzip into
wget_unzip()
    rm -rv $OUTPUT1
    mkdir -pv $(dirname $OUTPUT0)
    wget --output-document="$OUTPUT0" "$URL"
    unzip -o "$OUTPUT0" -d $OUTPUT1
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;


; create input schema
$[SQL_DIR]/input/schema <- [method:psql_schema -timecheck]

; wards
URL="https://data.cityofchicago.org/api/geospatial/sp34-6z76?method=export&format=Shapefile"
$[DATA_DIR]/shapefiles/wards.zip, $[DATA_DIR]/shapefiles/wards/ <- [-timecheck method:wget_unzip]
$[SQL_DIR]/input/wards <- $[DATA_DIR]/shapefiles/wards/, $[SQL_DIR]/input/schema [method:import_shapefile]

; census tracts
URL="https://data.cityofchicago.org/api/geospatial/5jrd-6zik?method=export&format=Shapefile"
$[DATA_DIR]/shapefiles/census_tracts.zip, $[DATA_DIR]/shapefiles/census_tracts/ <- [-timecheck method:wget_unzip]
$[SQL_DIR]/input/census_tracts <- $[DATA_DIR]/shapefiles/census_tracts/, $[SQL_DIR]/input/schema [method:import_shapefile]

; addresses
;URL="https://datacatalog.cookcountyil.gov/api/geospatial/jev2-4wjs?method=export&format=Shapefile"
;$[DATA_DIR]/shapefiles/addresses.zip, $[DATA_DIR]/shapefiles/addresses/ <- [-timecheck method:wget_unzip]
;$[SQL_DIR]/input/addresses <- $[DATA_DIR]/shapefiles/addresses/, $[SQL_DIR]/input/schema [method:import_shapefile]

; community areas
URL="https://data.cityofchicago.org/api/geospatial/cauq-8yn6?method=export&format=Shapefile"
$[DATA_DIR]/shapefiles/community_areas.zip, $[DATA_DIR]/shapefiles/community_areas/ <- [-timecheck method:wget_unzip]
$[SQL_DIR]/input/community_areas <- $[DATA_DIR]/shapefiles/community_areas/, $[SQL_DIR]/input/schema [method:import_shapefile]

; zip codes
URL="https://data.cityofchicago.org/api/geospatial/gdcf-axmw?method=export&format=Shapefile"
$[DATA_DIR]/shapefiles/zip_codes.zip, $[DATA_DIR]/shapefiles/zip_codes/ <- [-timecheck method:wget_unzip]
$[SQL_DIR]/input/zip_codes <- $[DATA_DIR]/shapefiles/zip_codes/, $[SQL_DIR]/input/schema [method:import_shapefile]

; census blocks
URL="https://data.cityofchicago.org/api/geospatial/mfzt-js4n?method=export&format=Shapefile"
$[DATA_DIR]/shapefiles/census_blocks.zip, $[DATA_DIR]/shapefiles/census_blocks/ <- [-timecheck method:wget_unzip]
$[SQL_DIR]/input/census_blocks <- $[DATA_DIR]/shapefiles/census_blocks/, $[SQL_DIR]/input/schema [method:import_shapefile]

; assessor
$[SQL_DIR]/input/assessor <- input/assessor.sh, $[ASSESSOR_FILE], $[SQL_DIR]/input/schema
    $INPUT $INPUT1 && touch $OUTPUT

; old blood tests, $[M7_FILE]
$[SQL_DIR]/input/m7 <- input/m7.sh, $[M7_FILE], $[SQL_DIR]/input/schema
    $INPUT $INPUT1 && touch $OUTPUT

; current blood tests
$[SQL_DIR]/input/currbllshort <- input/currbllshort.sh, $[CURRBLLSHORT_FILE], $[SQL_DIR]/input/schema
    $INPUT $INPUT1 && touch $OUTPUT

; census surname ethnicity
; documentation: http://www2.census.gov/topics/genealogy/2000surnames/surnames.pdf
$[DATA_DIR]/surnames/names.zip <- [-timecheck]
    mkdir -p `dirname $OUTPUT`
    wget -O $OUTPUT http://www2.census.gov/topics/genealogy/2000surnames/names.zip

$[DATA_DIR]/surnames/app_c.csv <- $[DATA_DIR]/surnames/names.zip
    unzip -o $INPUT -d `dirname $OUTPUT` && touch $OUTPUT # update timestamp

; remove suprressed values
$[DATA_DIR]/surnames/surnames.csv <- $[DATA_DIR]/surnames/app_c.csv
    cat $INPUT | sed 's/(S)/0/g' > $OUTPUT

$[SQL_DIR]/input/surnames <- input/surnames.sql, $[DATA_DIR]/surnames/surnames.csv, $[SQL_DIR]/input/schema [method:psql]

; download, unzip, and import buildings data
$[DATA_DIR]/shapefiles/buildings/data/Buildings.zip <- [-timecheck]
    git clone https://github.com/Chicago/osd-building-footprints.git $(dirname $(dirname $OUTPUT))

$[DATA_DIR]/shapefiles/buildings/data/shp/ <- $[DATA_DIR]/shapefiles/buildings/data/Buildings.zip [-timecheck]
    unzip $INPUT -d $OUTPUT

$[SQL_DIR]/input/buildings <- $[DATA_DIR]/shapefiles/buildings/data/shp/, $[SQL_DIR]/input/schema [method:import_shapefile]

; download and import building permit data
$[DATA_DIR]/building_permits.csv <- [-timecheck]
	wget -O- "https://data.cityofchicago.org/api/views/ydr8-5enu/rows.csv?accessType=DOWNLOAD" | sed 's/\$//g' > $OUTPUT
$[SQL_DIR]/input/building_permits <- input/building_permits.sql, $[DATA_DIR]/building_permits.csv, $[SQL_DIR]/input/schema [method:psql]

; download and import building violations data
$[DATA_DIR]/building_violations.csv <- [-timecheck]
	wget -O- "https://data.cityofchicago.org/api/views/22u3-xenr/rows.csv?accessType=DOWNLOAD" | sed 's/, ,/,,/g' > $OUTPUT
$[SQL_DIR]/input/building_violations <- input/building_violations.sql, $[DATA_DIR]/building_violations.csv, $[SQL_DIR]/input/schema [method:psql]

; selected acs variables copied to lead db via csv
; switch to acs profile
%include $[ACS_PROFILE]
$[DATA_DIR]/acs.csv <- input/acs/download.py
    python $INPUT $OUTPUT
%include $[PROFILE]

$[SQL_DIR]/input/acs <- input/acs/import.py, $[DATA_DIR]/acs.csv
    python $INPUT $INPUT1 && touch $OUTPUT

$[SQL_DIR]/input/labs <- input/labs.sql, $[LABS_FILE] [method:psql]
